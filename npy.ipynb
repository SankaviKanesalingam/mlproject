{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "version": "3.6.4",
      "file_extension": ".py",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "name": "python",
      "mimetype": "text/x-python"
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [],
      "dockerImageVersionId": 30213,
      "isInternetEnabled": false,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": false
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SankaviKanesalingam/mlproject/blob/main/npy.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "_HDihLc0SRz_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# <center>★ ML Project - Object Detection ★\n",
        "#### <center> ***Domain : Computer Vision***"
      ],
      "metadata": {
        "id": "JvE5VYZ0SR0J"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "8HRigSt-SR0Q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<center> <img src=\"https://raw.githubusercontent.com/Masterx-AI/Project_Object_Detection_Yolo_V4/main/result.jpg\" style=\"width: 600px;\"/> <center/>"
      ],
      "metadata": {
        "id": "BqHpHtOcSR0S"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "14S5F-43SR0V"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Description:\n",
        "\n",
        "OpenCV is the huge open-source library for computer vision, machine learning, and image processing and now it plays a major role in real-time operation which is very important in today’s systems. By using it, one can process images and videos to identify objects, faces, or even the handwriting of a human. This article focuses on detecting objects.\n",
        "\n",
        "Object Detection is a computer technology related to computer vision, image processing, and deep learning that deals with detecting instances of objects in images and videos. We will do object detection in this article using something known as haar cascades.\n",
        "\n",
        "YOLOv4 is a one-stage object detection model that improves on YOLOv3 with several bags of tricks and modules introduced in the literature. The components section below details the tricks and modules used.\n",
        "\n",
        "\n",
        "### Acknowledgement:\n",
        "OpenCV Library developed by Intel\n",
        "\n",
        "### Objective:\n",
        "- Object Detection with OpenCV using Yolo V4"
      ],
      "metadata": {
        "id": "wiu-w8DhSR0W"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "IRHdRXSaSR0Y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# <center> 1. Data Exploration"
      ],
      "metadata": {
        "id": "nmQMMzP3SR0g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import cv2 # openCV\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.rcParams[\"figure.figsize\"]=[12,8]\n",
        "\n",
        "# check the opencv version\n",
        "print(cv2.__version__)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-08-10T07:10:02.623559Z",
          "iopub.execute_input": "2022-08-10T07:10:02.624692Z",
          "iopub.status.idle": "2022-08-10T07:10:02.63139Z",
          "shell.execute_reply.started": "2022-08-10T07:10:02.624622Z",
          "shell.execute_reply": "2022-08-10T07:10:02.630271Z"
        },
        "trusted": true,
        "id": "gNUSPGi4SR0k"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "url = 'https://raw.githubusercontent.com/Masterx-AI/Project_Object_Detection_Yolo_V4/main/people_bicycles.jpg'\n",
        "r = requests.get(url, allow_redirects=True)\n",
        "open('people_bicycles.jpg', 'wb').write(r.content)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-08-10T07:14:33.365457Z",
          "iopub.execute_input": "2022-08-10T07:14:33.365924Z",
          "iopub.status.idle": "2022-08-10T07:14:33.650986Z",
          "shell.execute_reply.started": "2022-08-10T07:14:33.365881Z",
          "shell.execute_reply": "2022-08-10T07:14:33.64905Z"
        },
        "trusted": true,
        "id": "Zv03CPKbSR0o"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Reading the image file\n",
        "test_img = cv2.imread('people_bicycles.jpg')\n",
        "img = cv2.cvtColor(test_img, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "# Plotting the image\n",
        "def plot_image(img, cmap=None):\n",
        "    plt.imshow(img, cmap=cmap)\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "\n",
        "plot_image(img)\n",
        "plt.show()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-08-10T07:14:34.534016Z",
          "iopub.execute_input": "2022-08-10T07:14:34.535562Z",
          "iopub.status.idle": "2022-08-10T07:14:35.001596Z",
          "shell.execute_reply.started": "2022-08-10T07:14:34.535502Z",
          "shell.execute_reply": "2022-08-10T07:14:34.999855Z"
        },
        "trusted": true,
        "id": "wCSty6O1SR02"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "Gurdz7iHSR06"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# <center> 2. Image Processing"
      ],
      "metadata": {
        "id": "ybOeDGBvSR07"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# first create a directory to store the model\n",
        "%mkdir model\n",
        "\n",
        "# enter the directory and download the necessary files\n",
        "%cd model\n",
        "!wget https://github.com/AlexeyAB/darknet/releases/download/darknet_yolo_v3_optimal/yolov4.weights\n",
        "!wget https://raw.githubusercontent.com/AlexeyAB/darknet/master/cfg/yolov4.cfg\n",
        "!wget https://raw.githubusercontent.com/AlexeyAB/darknet/master/data/coco.names\n",
        "%cd .."
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-08-10T07:16:25.805149Z",
          "iopub.execute_input": "2022-08-10T07:16:25.805604Z",
          "iopub.status.idle": "2022-08-10T07:16:32.536148Z",
          "shell.execute_reply.started": "2022-08-10T07:16:25.805565Z",
          "shell.execute_reply": "2022-08-10T07:16:32.534359Z"
        },
        "trusted": true,
        "id": "_axecbwuSR08"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Converting to blob object\n",
        "\n",
        "scalefactor = 1.0/255.0\n",
        "new_size = (416, 416)\n",
        "blob = cv2.dnn.blobFromImage(test_img, scalefactor, new_size, swapRB=True, crop=False)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-08-10T07:16:34.818728Z",
          "iopub.execute_input": "2022-08-10T07:16:34.819577Z",
          "iopub.status.idle": "2022-08-10T07:16:34.831989Z",
          "shell.execute_reply.started": "2022-08-10T07:16:34.819531Z",
          "shell.execute_reply": "2022-08-10T07:16:34.830773Z"
        },
        "trusted": true,
        "id": "0UOBvYyWSR1D"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# define class labels\n",
        "class_labels_path = \"model/coco.names\"\n",
        "class_labels = open(class_labels_path).read().strip().split(\"\\n\")\n",
        "class_labels\n",
        "\n",
        "# declare repeating bounding box colors for each class\n",
        "# 1st: create a list colors as an RGB string array\n",
        "# Example: Red, Green, Blue, Yellow, Magenda\n",
        "class_colors = [\"255,0,0\",\"0,255,0\",\"0,0,255\",\"255,155,0\",\"255,0, 255\"]\n",
        "\n",
        "#2nd: split the array on comma-separated strings and for change each string type to integer\n",
        "class_colors = [np.array(every_color.split(\",\")).astype(\"int\") for every_color in class_colors]\n",
        "\n",
        "#3rd: convert the array or arrays to a numpy array\n",
        "class_colors = np.array(class_colors)\n",
        "\n",
        "#4th: tile this to get 80 class colors, i.e. as many as the classes(16 rows of 5cols each).\n",
        "# If you want unique colors for each class you may randomize the color generation or set them manually\n",
        "class_colors = np.tile(class_colors,(16,1))\n",
        "\n",
        "def colored(r, g, b, text):\n",
        "    return \"\\033[38;2;{};{};{}m{} \\033[38;2;255;255;255m\".format(r, g, b, text)\n",
        "\n",
        "for i in range(16):\n",
        "    line = \"\"\n",
        "    for j in range(5):\n",
        "        class_id = i*5 + j\n",
        "        class_id_str = str(class_id)\n",
        "        text = \"class\" + class_id_str\n",
        "        colored_text = colored(class_colors[class_id][0], class_colors[class_id][1], class_colors[class_id][2], text)\n",
        "        line += colored_text\n",
        "    print(line)\n",
        "\n",
        "# or select the colors randomly\n",
        "class_colors = np.random.randint(0, 255, size=(len(class_labels), 3), dtype=\"uint8\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-08-10T07:16:39.528311Z",
          "iopub.execute_input": "2022-08-10T07:16:39.528752Z",
          "iopub.status.idle": "2022-08-10T07:16:39.546025Z",
          "shell.execute_reply.started": "2022-08-10T07:16:39.528718Z",
          "shell.execute_reply": "2022-08-10T07:16:39.544803Z"
        },
        "trusted": true,
        "id": "w2gwSLOTSR1E"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "i-U2a7i2SR1F"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# <center>  3. Object Detection"
      ],
      "metadata": {
        "id": "bS7xoa3cSR1L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the pre-trained model\n",
        "yolo_model = cv2.dnn.readNetFromDarknet('model/yolov4.cfg','model/yolov4.weights')\n",
        "\n",
        "# Read the network layers/components. The YOLO V4 neural network has 379 components. They consist of convolutional layers (conv), rectifier linear units (relu) etc.:\n",
        "model_layers = yolo_model.getLayerNames()\n",
        "print(\"number of network components: \" + str(len(model_layers)))\n",
        "# print(model_layers)\n",
        "\n",
        "# extract the output layers in the code that follows:\n",
        "# - model_layer[0]: returns the index of each output layer in the range of 1 to 379\n",
        "# - model_layer[0] - 1: corrects  this to the range of 0 to 378\n",
        "# - model_layers[model_layer[0] - 1]: returns the indexed layer name\n",
        "output_layers = [model_layers[model_layer - 1] for model_layer in yolo_model.getUnconnectedOutLayers()]\n",
        "\n",
        "# YOLOv4 deploys the same YOLO head as YOLOv3 for detection with the anchor based detection steps, and three levels of detection granularity.\n",
        "print(output_layers)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-08-10T07:16:42.599451Z",
          "iopub.execute_input": "2022-08-10T07:16:42.600227Z",
          "iopub.status.idle": "2022-08-10T07:16:42.858531Z",
          "shell.execute_reply.started": "2022-08-10T07:16:42.600186Z",
          "shell.execute_reply": "2022-08-10T07:16:42.857153Z"
        },
        "trusted": true,
        "id": "gktkZLA2SR1N"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# input pre-processed blob into the model\n",
        "yolo_model.setInput(blob)\n",
        "\n",
        "# compute the forward pass for the input, storing the results per output layer in a list\n",
        "obj_detections_in_layers = yolo_model.forward(output_layers)\n",
        "\n",
        "# verify the number of sets of detections\n",
        "print(\"number of sets of detections: \" + str(len(obj_detections_in_layers)))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-08-10T07:16:44.449082Z",
          "iopub.execute_input": "2022-08-10T07:16:44.45042Z",
          "iopub.status.idle": "2022-08-10T07:16:45.928748Z",
          "shell.execute_reply.started": "2022-08-10T07:16:44.450367Z",
          "shell.execute_reply": "2022-08-10T07:16:45.927046Z"
        },
        "trusted": true,
        "id": "s9Wtr0HvSR1Q"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "def object_detection_analysis(test_image, obj_detections_in_layers, confidence_threshold):\n",
        "\n",
        "  # get the image dimensions\n",
        "  img_height = test_img.shape[0]\n",
        "  img_width = test_img.shape[1]\n",
        "\n",
        "  result = test_image.copy()\n",
        "\n",
        "  # loop over each output layer\n",
        "  for object_detections_in_single_layer in obj_detections_in_layers:\n",
        "    # loop over the detections in each layer\n",
        "      for object_detection in object_detections_in_single_layer:\n",
        "        # obj_detection[1]: bbox center pt_x\n",
        "        # obj_detection[2]: bbox center pt_y\n",
        "        # obj_detection[3]: bbox width\n",
        "        # obj_detection[4]: bbox height\n",
        "        # obj_detection[5]: confidence scores for all detections within the bbox\n",
        "\n",
        "        # get the confidence scores of all objects detected with the bounding box\n",
        "        prediction_scores = object_detection[5:]\n",
        "        # consider the highest score being associated with the winning class\n",
        "        # get the class ID from the index of the highest score\n",
        "        predicted_class_id = np.argmax(prediction_scores)\n",
        "        # get the prediction confidence\n",
        "        prediction_confidence = prediction_scores[predicted_class_id]\n",
        "\n",
        "        # consider object detections with confidence score higher than threshold\n",
        "        if prediction_confidence > confidence_threshold:\n",
        "            # get the predicted label\n",
        "            predicted_class_label = class_labels[predicted_class_id]\n",
        "            # compute the bounding box coordinates scaled for the input image\n",
        "            # scaling is a multiplication of the float coordinate with the appropriate  image dimension\n",
        "            bounding_box = object_detection[0:4] * np.array([img_width, img_height, img_width, img_height])\n",
        "            # get the bounding box centroid (x,y), width and height as integers\n",
        "            (box_center_x_pt, box_center_y_pt, box_width, box_height) = bounding_box.astype(\"int\")\n",
        "            # to get the start x and y coordinates we to subtract from the centroid half the width and half the height respectively\n",
        "            # for even values of width and height of bboxes adjacent to the  image border\n",
        "            #  this may generate a -1 which is prevented by the max() operator below\n",
        "            start_x_pt = max(0, int(box_center_x_pt - (box_width / 2)))\n",
        "            start_y_pt = max(0, int(box_center_y_pt - (box_height / 2)))\n",
        "            end_x_pt = start_x_pt + box_width\n",
        "            end_y_pt = start_y_pt + box_height\n",
        "\n",
        "            # get a random mask color from the numpy array of colors\n",
        "            box_color = class_colors[predicted_class_id]\n",
        "\n",
        "            # convert the color numpy array as a list and apply to text and box\n",
        "            box_color = [int(c) for c in box_color]\n",
        "\n",
        "            # print the prediction in console\n",
        "            predicted_class_label = \"{}: {:.2f}%\".format(predicted_class_label, prediction_confidence * 100)\n",
        "            print(\"predicted object {}\".format(predicted_class_label))\n",
        "\n",
        "            # draw the rectangle and text in the image\n",
        "            cv2.rectangle(result, (start_x_pt, start_y_pt), (end_x_pt, end_y_pt), box_color, 1)\n",
        "            cv2.putText(result, predicted_class_label, (start_x_pt, start_y_pt-5), cv2.FONT_HERSHEY_SIMPLEX, 0.5, box_color, 1)\n",
        "  return result\n",
        "\n",
        "confidence_threshold = 0.2\n",
        "result_raw = object_detection_analysis(test_img, obj_detections_in_layers, confidence_threshold)\n",
        "\n",
        "result_img = cv2.cvtColor(result_raw, cv2.COLOR_BGR2RGB)\n",
        "plt.imshow(result_img)\n",
        "plt.show()"
      ],
      "metadata": {
        "scrolled": true,
        "execution": {
          "iopub.status.busy": "2022-08-10T07:16:51.44859Z",
          "iopub.execute_input": "2022-08-10T07:16:51.44903Z",
          "iopub.status.idle": "2022-08-10T07:16:52.045832Z",
          "shell.execute_reply.started": "2022-08-10T07:16:51.448995Z",
          "shell.execute_reply": "2022-08-10T07:16:52.04386Z"
        },
        "trusted": true,
        "id": "LHcQRn0rSR1S"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "class_ids_list = []\n",
        "boxes_list = []\n",
        "confidences_list = []"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-08-10T07:16:57.854514Z",
          "iopub.execute_input": "2022-08-10T07:16:57.854993Z",
          "iopub.status.idle": "2022-08-10T07:16:57.86077Z",
          "shell.execute_reply.started": "2022-08-10T07:16:57.854954Z",
          "shell.execute_reply": "2022-08-10T07:16:57.859477Z"
        },
        "trusted": true,
        "id": "rqOumoB3SR1a"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "def object_detection_attributes(test_image, obj_detections_in_layers, confidence_threshold):\n",
        "  # get the image dimensions\n",
        "  img_height = test_img.shape[0]\n",
        "  img_width = test_img.shape[1]\n",
        "\n",
        "  # loop over each output layer\n",
        "  for object_detections_in_single_layer in obj_detections_in_layers:\n",
        "    # loop over the detections in each layer\n",
        "    for object_detection in object_detections_in_single_layer:\n",
        "      # get the confidence scores of all objects detected with the bounding box\n",
        "      prediction_scores = object_detection[5:]\n",
        "      # consider the highest score being associated with the winning class\n",
        "      # get the class ID from the index of the highest score\n",
        "      predicted_class_id = np.argmax(prediction_scores)\n",
        "      # get the prediction confidence\n",
        "      prediction_confidence = prediction_scores[predicted_class_id]\n",
        "\n",
        "      # consider object detections with confidence score higher than threshold\n",
        "      if prediction_confidence > confidence_threshold:\n",
        "        # get the predicted label\n",
        "        predicted_class_label = class_labels[predicted_class_id]\n",
        "        # compute the bounding box coordinates scaled for the input image\n",
        "        bounding_box = object_detection[0:4] * np.array([img_width, img_height, img_width, img_height])\n",
        "        (box_center_x_pt, box_center_y_pt, box_width, box_height) = bounding_box.astype(\"int\")\n",
        "        start_x_pt = max(0, int(box_center_x_pt - (box_width / 2)))\n",
        "        start_y_pt = max(0, int(box_center_y_pt - (box_height / 2)))\n",
        "\n",
        "        # update the 3 lists for nms processing\n",
        "        # - confidence is needed as a float\n",
        "        # - the bbox info has the openCV Rect format\n",
        "        class_ids_list.append(predicted_class_id)\n",
        "        confidences_list.append(float(prediction_confidence))\n",
        "        boxes_list.append([int(start_x_pt), int(start_y_pt), int(box_width), int(box_height)])"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-08-10T07:16:59.321509Z",
          "iopub.execute_input": "2022-08-10T07:16:59.321914Z",
          "iopub.status.idle": "2022-08-10T07:16:59.333885Z",
          "shell.execute_reply.started": "2022-08-10T07:16:59.321881Z",
          "shell.execute_reply": "2022-08-10T07:16:59.332326Z"
        },
        "trusted": true,
        "id": "EAc0mXw6SR1b"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "score_threshold = 0.5\n",
        "object_detection_attributes(test_img, obj_detections_in_layers, score_threshold)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-08-10T07:17:00.544878Z",
          "iopub.execute_input": "2022-08-10T07:17:00.545823Z",
          "iopub.status.idle": "2022-08-10T07:17:00.602468Z",
          "shell.execute_reply.started": "2022-08-10T07:17:00.545782Z",
          "shell.execute_reply": "2022-08-10T07:17:00.60158Z"
        },
        "trusted": true,
        "id": "3Ipb4SchSR1c"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# NMS for a set of overlapping bboxes returns the ID of the one with highest\n",
        "# confidence score while suppressing all others (non maxima)\n",
        "# - score_threshold: a threshold used to filter boxes by score\n",
        "# - nms_threshold: a threshold used in non maximum suppression.\n",
        "\n",
        "score_threshold = 0.5\n",
        "nms_threshold = 0.4\n",
        "winner_ids = cv2.dnn.NMSBoxes(boxes_list, confidences_list, score_threshold, nms_threshold)\n",
        "\n",
        "# loop through the final set of detections remaining after NMS and draw bounding box and write text\n",
        "for winner_id in winner_ids:\n",
        "    max_class_id = winner_id\n",
        "    box = boxes_list[max_class_id]\n",
        "    start_x_pt = box[0]\n",
        "    start_y_pt = box[1]\n",
        "    box_width = box[2]\n",
        "    box_height = box[3]\n",
        "\n",
        "    #get the predicted class id and label\n",
        "    predicted_class_id = class_ids_list[max_class_id]\n",
        "    predicted_class_label = class_labels[predicted_class_id]\n",
        "    prediction_confidence = confidences_list[max_class_id]\n",
        "\n",
        "    #obtain the bounding box end coordinates\n",
        "    end_x_pt = start_x_pt + box_width\n",
        "    end_y_pt = start_y_pt + box_height\n",
        "\n",
        "    #get a random mask color from the numpy array of colors\n",
        "    box_color = class_colors[predicted_class_id]\n",
        "\n",
        "    #convert the color numpy array as a list and apply to text and box\n",
        "    box_color = [int(c) for c in box_color]\n",
        "\n",
        "    # print the prediction in console\n",
        "    predicted_class_label = \"{}: {:.2f}%\".format(predicted_class_label, prediction_confidence * 100)\n",
        "    print(\"predicted object {}\".format(predicted_class_label))\n",
        "\n",
        "    # draw rectangle and text in the image\n",
        "    cv2.rectangle(test_img, (start_x_pt, start_y_pt), (end_x_pt, end_y_pt), box_color, 2)\n",
        "    cv2.putText(test_img, predicted_class_label, (start_x_pt, start_y_pt-5), cv2.FONT_HERSHEY_SIMPLEX, 0.5, box_color, 2)\n",
        "\n",
        "test_imgz = cv2.cvtColor(test_img, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "plt.imshow(test_imgz)\n",
        "plt.show()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-08-10T07:17:01.625856Z",
          "iopub.execute_input": "2022-08-10T07:17:01.626315Z",
          "iopub.status.idle": "2022-08-10T07:17:02.104074Z",
          "shell.execute_reply.started": "2022-08-10T07:17:01.626262Z",
          "shell.execute_reply": "2022-08-10T07:17:02.102653Z"
        },
        "trusted": true,
        "id": "Znw_2v8mSR1j"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "W9ohTzC8SR1k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# <center> 4. Video Processing"
      ],
      "metadata": {
        "id": "h2o2Qc2VSR1l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Incase using a youtube video\n",
        "\n",
        "# import pafy\n",
        "\n",
        "# url = \"https://www.youtube.com/watch?v=eldQI2ONYE0&ab_channel=Angeles69\"\n",
        "# video = pafy.new(url)\n",
        "# best = video.getbest(preftype=\"mp4\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-08-10T07:17:13.233108Z",
          "iopub.execute_input": "2022-08-10T07:17:13.23354Z",
          "iopub.status.idle": "2022-08-10T07:17:13.239974Z",
          "shell.execute_reply.started": "2022-08-10T07:17:13.233507Z",
          "shell.execute_reply": "2022-08-10T07:17:13.23857Z"
        },
        "trusted": true,
        "id": "h9a3imNDSR1l"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "def object_detection_analysis_with_nms(test_img, class_labels, class_colors, obj_detections_in_layers, score_threshold, nms_threshold):\n",
        "\n",
        "    # get the image dimensions\n",
        "    img_height = test_img.shape[0]\n",
        "    img_width = test_img.shape[1]\n",
        "\n",
        "    result = test_img.copy()\n",
        "\n",
        "    # declare lists for the arguments of interest: classID, bbox info, detection confidences\n",
        "    class_ids_list = []\n",
        "    boxes_list = []\n",
        "    confidences_list = []\n",
        "    # loop over each output layer\n",
        "    for object_detections_in_single_layer in obj_detections_in_layers:\n",
        "        # loop over the detections in each layer\n",
        "        for object_detection in object_detections_in_single_layer:\n",
        "            # get the confidence scores of all objects detected with the bounding box\n",
        "            prediction_scores = object_detection[5:]\n",
        "            # consider the highest score being associated with the winning class\n",
        "            # get the class ID from the index of the highest score\n",
        "            predicted_class_id = np.argmax(prediction_scores)\n",
        "            # get the prediction confidence\n",
        "            prediction_confidence = prediction_scores[predicted_class_id]\n",
        "\n",
        "            # consider object detections with confidence score higher than threshold\n",
        "            if prediction_confidence > score_threshold:\n",
        "                # get the predicted label\n",
        "                predicted_class_label = class_labels[predicted_class_id]\n",
        "                # compute the bounding box cooridnates scaled for the input image\n",
        "                bounding_box = object_detection[0:4] * np.array([img_width, img_height, img_width, img_height])\n",
        "                (box_center_x_pt, box_center_y_pt, box_width, box_height) = bounding_box.astype(\"int\")\n",
        "                start_x_pt = max(0, int(box_center_x_pt - (box_width / 2)))\n",
        "                start_y_pt = max(0, int(box_center_y_pt - (box_height / 2)))\n",
        "\n",
        "                # update the 3 lists for nms processing\n",
        "                # - confidence is needed as a float\n",
        "                # - the bbox info has the openCV Rect format\n",
        "                class_ids_list.append(predicted_class_id)\n",
        "                confidences_list.append(float(prediction_confidence))\n",
        "                boxes_list.append([int(start_x_pt), int(start_y_pt), int(box_width), int(box_height)])"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-08-10T07:18:45.087931Z",
          "iopub.execute_input": "2022-08-10T07:18:45.088434Z",
          "iopub.status.idle": "2022-08-10T07:18:45.100941Z",
          "shell.execute_reply.started": "2022-08-10T07:18:45.088394Z",
          "shell.execute_reply": "2022-08-10T07:18:45.099594Z"
        },
        "trusted": true,
        "id": "FRrIpQ3RSR1r"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Real-time video object detection\n",
        "\n",
        "\n",
        "new_width = 640\n",
        "new_height = 480\n",
        "dim = (new_width, new_height)\n",
        "\n",
        "cap = cv2.VideoCapture('London.mp4')  #best.url\n",
        "\n",
        "while cap.isOpened():\n",
        "    #get the current frame from video stream\n",
        "    ret,frame = cap.read()\n",
        "\n",
        "    frame = cv2.resize(frame, dim, interpolation = cv2.INTER_AREA)\n",
        "\n",
        "    blob = cv2.dnn.blobFromImage(frame, scalefactor, new_size, swapRB=True, crop=False)\n",
        "\n",
        "    # input pre-processed blob into the model\n",
        "    yolo_model.setInput(blob)\n",
        "\n",
        "    # compute the forward pass for the input, storing the results per output layer in a list\n",
        "    obj_detections_in_layers = yolo_model.forward(output_layers)\n",
        "\n",
        "#     # get  the object detections drawn on  the frame\n",
        "    frame, winner_boxes = object_detection_analysis_with_nms(frame, class_labels, class_colors, obj_detections_in_layers, score_threshold, nms_threshold)\n",
        "\n",
        "    #display the frame\n",
        "    cv2.imshow('Webcam', frame)\n",
        "    # if running outside Colab notebooks use:\n",
        "    # cv2.imshow(frame)\n",
        "\n",
        "    #terminate while loop if 'q' key is pressed - applicable outside the notebooks\n",
        "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "        break\n",
        "\n",
        "#releasing the stream and the camera\n",
        "cap.release()\n",
        "# cv2.destroyAllWindows()\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-08-10T07:18:09.529062Z",
          "iopub.execute_input": "2022-08-10T07:18:09.529633Z",
          "iopub.status.idle": "2022-08-10T07:18:09.541717Z",
          "shell.execute_reply.started": "2022-08-10T07:18:09.529593Z",
          "shell.execute_reply": "2022-08-10T07:18:09.539853Z"
        },
        "trusted": true,
        "id": "ONOCD8tFSR1s"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "pKTnL-HCSR1u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#<<<--------------------------------------THE END---------------------------------------->>>"
      ],
      "metadata": {
        "id": "GOylV4mySR1v"
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}